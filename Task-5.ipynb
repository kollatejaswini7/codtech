{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed765a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91939\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91939\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91939\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
      "Tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "Filtered Tokens (without stop words): ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'languages', ',', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', '.']\n",
      "Stemmed Tokens: ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n",
      "Lemmatized Tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'artificial', 'intelligence', 'concerned', 'interaction', 'computer', 'human', 'language', ',', 'particular', 'program', 'computer', 'process', 'analyze', 'large', 'amount', 'natural', 'language', 'data', '.']\n",
      "Word Embedding for 'language': [-8.23669601e-03  9.30240657e-03 -1.91607265e-04 -1.95375062e-03\n",
      "  4.59308457e-03 -4.10331972e-03  2.76850886e-03  6.95279799e-03\n",
      "  6.05347287e-03 -7.52749527e-03  9.38461069e-03  4.66597499e-03\n",
      "  3.96677339e-03 -6.23817882e-03  8.45445041e-03 -2.15923716e-03\n",
      "  8.83370079e-03 -5.37611637e-03 -8.13570246e-03  6.80812122e-03\n",
      "  1.66911993e-03 -2.19226582e-03  9.52217355e-03  9.49996151e-03\n",
      " -9.78520606e-03  2.50184117e-03  6.14947686e-03  3.86407622e-03\n",
      "  2.01501464e-03  4.39359632e-04  6.81891455e-04 -3.83103243e-03\n",
      " -7.13821640e-03 -2.10453407e-03  3.91556090e-03  8.82628746e-03\n",
      "  9.25638154e-03 -5.97112486e-03 -9.40408744e-03  9.75597464e-03\n",
      "  3.42616066e-03  5.15681226e-03  6.27075508e-03 -2.80186604e-03\n",
      "  7.32508348e-03  2.81882519e-03  2.86352914e-03 -2.38216389e-03\n",
      " -3.12442612e-03 -2.36213976e-03  4.27099923e-03  7.18403971e-05\n",
      " -9.58665088e-03 -9.66884475e-03 -6.14796765e-03 -1.15757495e-04\n",
      "  2.00388324e-03  9.41974390e-03  5.57641545e-03 -4.28782450e-03\n",
      "  2.70758348e-04  4.94652567e-03  7.70681957e-03 -1.14405854e-03\n",
      "  4.31373110e-03 -5.80044836e-03 -8.20566609e-04  8.10258929e-03\n",
      " -2.37148581e-03 -9.67246201e-03  5.78749320e-03 -3.91880237e-03\n",
      " -1.21806224e-03  9.97694302e-03 -2.24823505e-03 -4.75975499e-03\n",
      " -5.32819331e-03  6.98442804e-03 -5.70795173e-03  2.10873666e-03\n",
      " -5.25713200e-03  6.11768244e-03  4.36700927e-03  2.60833907e-03\n",
      " -1.48622715e-03 -2.75417720e-03  8.99956189e-03  5.21611329e-03\n",
      " -2.14661914e-03 -9.46001988e-03 -7.41839921e-03 -1.06991257e-03\n",
      " -7.96215783e-04 -2.56756158e-03  9.68952570e-03 -4.56187205e-04\n",
      "  5.87061467e-03 -7.46027566e-03 -2.49871588e-03 -5.55310771e-03]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Sample text data\n",
    "text_data = \"Natural language processing (NLP) is a subfield of linguistics, computer science, \" \\\n",
    "            \"and artificial intelligence concerned with the interactions between computers and human \" \\\n",
    "            \"languages, in particular how to program computers to process and analyze large amounts \" \\\n",
    "            \"of natural language data.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text_data)\n",
    "\n",
    "# Stop-word Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "# Word Embeddings (Word2Vec)\n",
    "sentences = [word_tokenize(sentence) for sentence in nltk.sent_tokenize(text_data)]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Test Word Embeddings\n",
    "word_embedding = word2vec_model.wv['language']\n",
    "\n",
    "# Print results\n",
    "print(\"Original Text:\", text_data)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Filtered Tokens (without stop words):\", filtered_tokens)\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "print(\"Lemmatized Tokens:\", lemmatized_tokens)\n",
    "print(\"Word Embedding for 'language':\", word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a31ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c7bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
